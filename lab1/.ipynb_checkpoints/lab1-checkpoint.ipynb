{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f82cc0-0753-4109-b448-7ddc636c99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "import sys\n",
    "sys.path.append('../lab0')\n",
    "import maze as mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "491411db-cb16-41ba-a7a5-691e38672520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implemented methods\n",
    "methods = ['DynProg', 'ValIter'];\n",
    "\n",
    "# Some colours\n",
    "LIGHT_RED    = '#FFC4CC';\n",
    "LIGHT_GREEN  = '#95FD99';\n",
    "BLACK        = '#000000';\n",
    "WHITE        = '#FFFFFF';\n",
    "LIGHT_PURPLE = '#E8D0FF';\n",
    "LIGHT_ORANGE = '#FAE0C3';\n",
    "\n",
    "class Maze1:\n",
    "     # Actions\n",
    "    STAY       = 0\n",
    "    MOVE_LEFT  = 1\n",
    "    MOVE_RIGHT = 2\n",
    "    MOVE_UP    = 3\n",
    "    MOVE_DOWN  = 4\n",
    "\n",
    "    # Give names to actions\n",
    "    actions_names = {\n",
    "        STAY: \"stay\",\n",
    "        MOVE_LEFT: \"move left\",\n",
    "        MOVE_RIGHT: \"move right\",\n",
    "        MOVE_UP: \"move up\",\n",
    "        MOVE_DOWN: \"move down\"\n",
    "    }\n",
    "    \n",
    "    def __init__(self, maze, weights=None, STEP_REWARD = 0, GOAL_REWARD = 0, random_rewards=False, min_move=1):\n",
    "        \"\"\" Constructor of the environment Maze.\n",
    "        \"\"\"\n",
    "        self.maze                     = maze;\n",
    "        self.win_state = self.__win_state()\n",
    "        self.actions                  = self.__actions();\n",
    "        self.states, self.map         = self.__states();\n",
    "        self.n_actions                = len(self.actions);\n",
    "        self.n_states                 = len(self.states);\n",
    "        self.min_move = min_move\n",
    "        self.transition_probabilities = self.__transitions();\n",
    "        \n",
    "        self.STEP_REWARD = STEP_REWARD\n",
    "        self.GOAL_REWARD = GOAL_REWARD\n",
    "        self.rewards                  = self.__rewards(weights=weights,\n",
    "                                                random_rewards=random_rewards);\n",
    "        \n",
    "        \n",
    "    def __win_state(self):\n",
    "        return tuple([i[0] for i in np.where(self.maze == 2)])        \n",
    "        \n",
    "    def __actions(self):\n",
    "        actions = dict();\n",
    "        actions[self.STAY]       = (0, 0);\n",
    "        actions[self.MOVE_LEFT]  = (0,-1);\n",
    "        actions[self.MOVE_RIGHT] = (0, 1);\n",
    "        actions[self.MOVE_UP]    = (-1,0);\n",
    "        actions[self.MOVE_DOWN]  = (1,0);\n",
    "        return actions;\n",
    "    \n",
    "    def __states(self):\n",
    "        states = dict()\n",
    "        map = dict()\n",
    "        s = 0\n",
    "        for i in range(self.maze.shape[0]):\n",
    "            for j in range(self.maze.shape[1]):\n",
    "                if maze[i,j] !=1:\n",
    "                    for k in range(self.maze.shape[0]):\n",
    "                        for m in range(self.maze.shape[1]):\n",
    "                            if maze[k,m] !=1:\n",
    "                                if ((i,j) != (k,m) and (i,j) != self.win_state):\n",
    "                                    states[s] = (i,j,k,m)\n",
    "                                    map[(i,j,k,m)] = s\n",
    "                                    s += 1\n",
    "\n",
    "        states[s] = (1,1,1,1) # Win state \n",
    "        map[(1,1,1,1)] = s\n",
    "        s+=1\n",
    "\n",
    "        states[s] = (-1,-1,-1,-1) #Lost state\n",
    "        map[(-1,-1,-1,-1)] = s\n",
    "        return states, map\n",
    "\n",
    "    def hitting_maze_walls(self,row, col):\n",
    "        return (row == -1) or (row == self.maze.shape[0]) or \\\n",
    "                  (col == -1) or (col == self.maze.shape[1]) or \\\n",
    "                  (self.maze[row,col] == 1);\n",
    "\n",
    "    def __moves(self,state,action):\n",
    "        #If win or loose stay there\n",
    "        if state == self.map[(-1,-1,-1,-1)] or state == self.map[(1,1,1,1)]:\n",
    "            return [state]\n",
    "        s = np.array(self.states[state])\n",
    "        \n",
    "        #Check viable moves\n",
    "        p_next = tuple(s[:2] + self.actions[action])\n",
    "        if self.hitting_maze_walls(p_next[0], p_next[1]):\n",
    "                  p_next = tuple(s[:2])\n",
    "                \n",
    "        mt_temp = [tuple(s[2:] + self.actions[i]) for i in range(self.min_move,5)]\n",
    "        mt_next= []\n",
    "        for mt in mt_temp:\n",
    "            if not self.hitting_maze_walls(mt[0], mt[1]):\n",
    "                  mt_next.append(mt)\n",
    "        \n",
    "        s_next = [p_next + mt for mt in mt_next]\n",
    "\n",
    "        #Check if game is finished\n",
    "        final = []\n",
    "        for i in s_next:\n",
    "            if i[:2] == i[2:]:\n",
    "                final.append((-1,-1,-1,-1))\n",
    "            elif i[:2] == self.win_state:\n",
    "                final.append((1,1,1,1))\n",
    "            else:\n",
    "                final.append(i)\n",
    "\n",
    "        if len(final) < 1:\n",
    "            return [state]\n",
    "        else:\n",
    "            return [self.map[i] for i in final]\n",
    "        \n",
    "    def __transitions(self):\n",
    "        dimensions = (self.n_states,self.n_states,self.n_actions)\n",
    "        transition_probabilities = np.zeros(dimensions)\n",
    "\n",
    "        for s in range(self.n_states):\n",
    "            for a in range(self.n_actions):\n",
    "                next_ss = self.__moves(s,a)\n",
    "                for next_s in next_ss:\n",
    "                    transition_probabilities[next_s,s,a] += 1/len(next_ss)\n",
    "\n",
    "        return transition_probabilities\n",
    "    \n",
    "    def __rewards(self, weights=None, random_rewards=None):\n",
    "        rewards = np.zeros((self.n_states, self.n_actions))\n",
    "        \n",
    "        for s in range(self.n_states):\n",
    "            for a in range(self.n_actions):\n",
    "                next_s = self.__moves(s,a)\n",
    "                for ns in next_s:\n",
    "                    if ns == self.n_states-2:\n",
    "                        rewards[s,a] = self.GOAL_REWARD\n",
    "                    #elif ns == self.n_states-1:\n",
    "                    #    rewards[s,a] = -self.GOAL_REWARD\n",
    "                    else:\n",
    "                        rewards[s,a] = self.STEP_REWARD\n",
    "        \n",
    "        return rewards\n",
    "    \n",
    "    def _move(self,state, action):\n",
    "        next_s = self.__moves(state, action)\n",
    "        return np.random.choice(next_s)\n",
    "        \n",
    "    def simulate(self, start, policy, method='DynProg'):\n",
    "        if method not in methods:\n",
    "            error = 'ERROR: the argument method must be in {}'.format(methods);\n",
    "            raise NameError(error);\n",
    "\n",
    "        path = list();\n",
    "        if method == 'DynProg':\n",
    "            # Deduce the horizon from the policy shape\n",
    "            horizon = policy.shape[1];\n",
    "            # Initialize current state and time\n",
    "            t = 0;\n",
    "            s = self.map[start];\n",
    "            # Add the starting position in the maze to the path\n",
    "            path.append(start);\n",
    "            while t < horizon-1:\n",
    "                # Move to next state given the policy and the current state\n",
    "                next_s = self._move(s,policy[s,t]);\n",
    "                # Add the position in the maze corresponding to the next state\n",
    "                # to the path\n",
    "                path.append(self.states[next_s])\n",
    "                # Update time and state for next iteration\n",
    "                t +=1;\n",
    "                s = next_s;\n",
    "        \n",
    "        if method == 'ValIter':\n",
    "            # Initialize current state, next state and time\n",
    "            t = 1;\n",
    "            s = self.map[start];\n",
    "            # Add the starting position in the maze to the path\n",
    "            path.append(start);\n",
    "            # Move to next state given the policy and the current state\n",
    "            next_s = self._move(s,policy[s]);\n",
    "            # Add the position in the maze corresponding to the next state\n",
    "            # to the path\n",
    "            path.append(self.states[next_s]);\n",
    "            \n",
    "            # Loop while state is not the goal or lost state\n",
    "            while s != self.n_states -1 and s!=self.n_states-2 and t <50 :\n",
    "                # Update state\n",
    "                s = next_s;\n",
    "                # Move to next state given the policy and the current state\n",
    "                next_s = self._move(s,policy[s]);\n",
    "                # Add the position in the maze corresponding to the next state\n",
    "                # to the path\n",
    "                path.append(self.states[next_s])\n",
    "                # Update time and state for next iteration\n",
    "                t +=1;\n",
    "        \n",
    "        return path\n",
    "\n",
    "def dynamic_programming(env, horizon):\n",
    "    p         = env.transition_probabilities;\n",
    "    r         = env.rewards;\n",
    "    n_states  = env.n_states;\n",
    "    n_actions = env.n_actions;\n",
    "    T         = horizon;\n",
    "\n",
    "    # The variables involved in the dynamic programming backwards recursions\n",
    "    V      = np.zeros((n_states, T+1));\n",
    "    policy = np.zeros((n_states, T+1));\n",
    "    Q      = np.zeros((n_states, n_actions));\n",
    "\n",
    "\n",
    "    # Initialization\n",
    "    Q            = np.copy(r);\n",
    "    V[:, T]      = np.max(Q,1);\n",
    "    policy[:, T] = np.argmax(Q,1);\n",
    "    V[env.n_states-2, T] = 1\n",
    "    \n",
    "    for t in range(T-1,-1,-1):\n",
    "        # Update the value function acccording to the bellman equation\n",
    "        for s in range(n_states):\n",
    "            for a in range(n_actions):\n",
    "                # Update of the temporary Q values\n",
    "                Q[s,a] = r[s,a] + np.dot(p[:,s,a],V[:,t+1])\n",
    "        # Update by taking the maximum Q value w.r.t the action a\n",
    "        V[:,t] = np.max(Q,1);\n",
    "        # The optimal action is the one that maximizes the Q function\n",
    "        policy[:,t] = np.argmax(Q,1);\n",
    "    \n",
    "    return V, policy\n",
    "\n",
    "def value_iteration(env, gamma, epsilon):\n",
    "    \"\"\" Solves the shortest path problem using value iteration\n",
    "        :input Maze env           : The maze environment in which we seek to\n",
    "                                    find the shortest path.\n",
    "        :input float gamma        : The discount factor.\n",
    "        :input float epsilon      : accuracy of the value iteration procedure.\n",
    "        :return numpy.array V     : Optimal values for every state at every\n",
    "                                    time, dimension S*T\n",
    "        :return numpy.array policy: Optimal time-varying policy at every state,\n",
    "                                    dimension S*T\n",
    "    \"\"\"\n",
    "    # The value itearation algorithm requires the knowledge of :\n",
    "    # - Transition probabilities\n",
    "    # - Rewards\n",
    "    # - State space\n",
    "    # - Action space\n",
    "    # - The finite horizon\n",
    "    p         = env.transition_probabilities;\n",
    "    r         = env.rewards;\n",
    "    n_states  = env.n_states;\n",
    "    n_actions = env.n_actions;\n",
    "\n",
    "    # Required variables and temporary ones for the VI to run\n",
    "    V   = np.zeros(n_states);\n",
    "    Q   = np.zeros((n_states, n_actions));\n",
    "    BV  = np.zeros(n_states);\n",
    "    # Iteration counter\n",
    "    n   = 0;\n",
    "    # Tolerance error\n",
    "    tol = (1 - gamma)* epsilon/gamma;\n",
    "    # Initialization of the VI\n",
    "    for s in range(n_states):\n",
    "        for a in range(n_actions):\n",
    "            Q[s, a] = r[s,a] + gamma*np.dot(p[:,s,a],V);\n",
    "    BV = np.max(Q, 1);\n",
    "    # Iterate until convergence\n",
    "    while np.linalg.norm(V - BV) >= tol and n < 200:\n",
    "        # Increment by one the numbers of iteration\n",
    "        n += 1;\n",
    "        # Update the value function\n",
    "        V = np.copy(BV);\n",
    "        # Compute the new BV\n",
    "        for s in range(n_states):\n",
    "            for a in range(n_actions):\n",
    "                Q[s, a] = r[s, a] + gamma*np.dot(p[:,s,a],V);\n",
    "        BV = np.max(Q, 1);\n",
    "        # Show error\n",
    "        #print(np.linalg.norm(V - BV))\n",
    "\n",
    "    # Compute policy\n",
    "    policy = np.argmax(Q,1);\n",
    "    # Return the obtained policy\n",
    "    return V, policy;\n",
    "\n",
    "def Q_learning(env, gamma, epsilon, n_episodes, n_steps):\n",
    "    rewards = env.rewards\n",
    "    start = env.map[(0,0,6,5)]\n",
    "    n_states = env.n_states\n",
    "    n_actions = env.n_actions\n",
    "    V      = np.zeros(n_states);\n",
    "    policy = np.zeros(n_states);\n",
    "    Q      = np.random.random((n_states, n_actions));\n",
    "    n      = np.ones((n_states, n_actions))\n",
    "    \n",
    "    initial_value = []\n",
    "    for episode in range(n_episodes):\n",
    "        s = start\n",
    "        initial_value.append(V[s])\n",
    "        print(f'Episode: {episode}')\n",
    "        for step in range(n_steps):\n",
    "            #Choose action epsilon-greedy\n",
    "            if np.random.uniform(0,1)< epsilon:\n",
    "                a = np.random.randint(env.n_actions)\n",
    "            else:\n",
    "                a = np.argmax(Q[s,:])\n",
    "            \n",
    "            R = rewards[s,a]\n",
    "            s_next = env._move(s,a)\n",
    "            \n",
    "            Q[s,a] = Q[s,a] + (1/n[s,a]**(2/3))*(R + gamma*np.max(Q[s_next,:]) - Q[s,a])\n",
    "            n[s,a] += 1\n",
    "            s=s_next\n",
    "            \n",
    "            \n",
    "            if s == env.map[(1,1,1,1)] or s == env.map[(1,1,1,1)]:\n",
    "                #Go to next episode\n",
    "                break\n",
    "        V[:] = np.max(Q,1)\n",
    "        policy = np.argmax(Q,1)\n",
    "        \n",
    "    return Q, policy,initial_value\n",
    "\n",
    "def sarsa(env, alpha, gamma, epsilon, n_episodes, n_steps):\n",
    "    rewards = env.rewards\n",
    "    start = env.map[(0,0,6,5)]\n",
    "    n_states = env.n_states\n",
    "    n_actions = env.n_actions\n",
    "    \n",
    "    V      = np.zeros(n_states);\n",
    "    policy = np.zeros(n_states);\n",
    "    Q      = np.random.random((n_states, n_actions));\n",
    "    n      = np.ones((n_states, n_actions))\n",
    "    \n",
    "    initial_value = []\n",
    "    for episode in range(n_episodes):\n",
    "        s = start\n",
    "        #Choose action epsilon-greedy\n",
    "        if np.random.uniform(0,1)< epsilon:\n",
    "            a = np.random.randint(env.n_actions)\n",
    "        else:\n",
    "            a = np.argmax(Q[s,:])\n",
    "\n",
    "        initial_value.append(V[s])\n",
    "        print(f'Episode: {episode}')\n",
    "        for step in range(n_steps):\n",
    "            R = rewards[s,a]\n",
    "            s_next = env._move(s,a)\n",
    "            \n",
    "            if np.random.uniform(0,1)< epsilon:\n",
    "                a_next = np.random.randint(env.n_actions)\n",
    "            else:\n",
    "                a_next = np.argmax(Q[s_next,:])\n",
    "            \n",
    "            Q[s,a] = Q[s,a] + (1/n[s,a]**(alpha))*(R + gamma*Q[s_next,a_next] - Q[s,a])\n",
    "            n[s,a] += 1\n",
    "            \n",
    "            s=s_next;a=a_next\n",
    "            if s == env.map[(1,1,1,1)] or s == env.map[(1,1,1,1)]:\n",
    "                #Go to next episode\n",
    "                break\n",
    "        V[:] = np.max(Q,1)\n",
    "        policy = np.argmax(Q,1)\n",
    "        \n",
    "    return Q, policy,initial_value\n",
    "\n",
    "def animate_solution(maze, path):\n",
    "\n",
    "    # Map a color to each cell in the maze\n",
    "    col_map = {0: WHITE, 1: BLACK, 2: LIGHT_GREEN, -6: LIGHT_RED, -1: LIGHT_RED};\n",
    "\n",
    "    # Size of the maze\n",
    "    rows,cols = maze.shape;\n",
    "\n",
    "    # Create figure of the size of the maze\n",
    "    fig = plt.figure(1, figsize=(cols,rows));\n",
    "\n",
    "    # Remove the axis ticks and add title title\n",
    "    ax = plt.gca();\n",
    "    ax.set_title('Policy simulation');\n",
    "    ax.set_xticks([]);\n",
    "    ax.set_yticks([]);\n",
    "\n",
    "    # Give a color to each cell\n",
    "    colored_maze = [[col_map[maze[j,i]] for i in range(cols)] for j in range(rows)];\n",
    "\n",
    "    # Create figure of the size of the maze\n",
    "    fig = plt.figure(1, figsize=(cols,rows))\n",
    "\n",
    "    # Create a table to color\n",
    "    grid = plt.table(cellText=None,\n",
    "                     cellColours=colored_maze,\n",
    "                     cellLoc='center',\n",
    "                     loc=(0,0),\n",
    "                     edges='closed');\n",
    "\n",
    "    # Modify the hight and width of the cells in the table\n",
    "    tc = grid.properties()['children']\n",
    "    for cell in tc:\n",
    "        cell.set_height(1.0/rows);\n",
    "        cell.set_width(1.0/cols);\n",
    "\n",
    "    \n",
    "    end = tuple([i[0] for i in np.where(maze == 2)])\n",
    "    # Update the color at each frame\n",
    "    over = False\n",
    "    for i in range(len(path)):\n",
    "        if (path[i] == (1,1,1,1) or path[i] ==(-1,-1,-1,-1)) and not over:\n",
    "            over=True\n",
    "            grid.get_celld()[(path[i-1][:2])].set_facecolor(col_map[maze[path[i-1][:2]]])\n",
    "            grid.get_celld()[(path[i-1][:2])].get_text().set_text('')\n",
    "            grid.get_celld()[(path[i-1][2:])].set_facecolor(col_map[maze[path[i-1][2:]]])\n",
    "            grid.get_celld()[(path[i-1][2:])].get_text().set_text('')\n",
    "        if not over:\n",
    "            if i > 0:\n",
    "                if path[i][:2] != path[i-1][:2]:\n",
    "                    grid.get_celld()[(path[i-1][:2])].set_facecolor(col_map[maze[path[i-1][:2]]])\n",
    "                    grid.get_celld()[(path[i-1][:2])].get_text().set_text('')\n",
    "                if path[i][2:] != path[i-1][2:]:\n",
    "                    grid.get_celld()[(path[i-1][2:])].set_facecolor(col_map[maze[path[i-1][2:]]])\n",
    "                    grid.get_celld()[(path[i-1][2:])].get_text().set_text('')\n",
    "            grid.get_celld()[(path[i][:2])].set_facecolor(LIGHT_ORANGE)\n",
    "            grid.get_celld()[(path[i][:2])].get_text().set_text('Player')\n",
    "\n",
    "            grid.get_celld()[(path[i][2:])].set_facecolor(LIGHT_ORANGE)\n",
    "            grid.get_celld()[(path[i][2:])].get_text().set_text('MT')\n",
    "        \n",
    "        else:\n",
    "            if path[i] == (1,1,1,1):\n",
    "                grid.get_celld()[(end)].set_facecolor(LIGHT_GREEN)\n",
    "                grid.get_celld()[(end)].get_text().set_text('Win')\n",
    "            else:\n",
    "                grid.get_celld()[(end)].set_facecolor(LIGHT_RED)\n",
    "                grid.get_celld()[(end)].get_text().set_text('Lost')\n",
    "            \n",
    "        display.display(fig)\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(0.1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "050370ff-b612-4f87-99d6-f62da345313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = np.array([\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44612f7a-4733-4340-a5ca-9dc330e3c98e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dyn P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f6091-c03d-46cc-a239-0d3327bf5813",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Maze1(maze)\n",
    "start = (0,0,6,5)\n",
    "V, p = dynamic_programming(env, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceaed94-8425-4b53-9348-23ebe399d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = (0,0,6,5)\n",
    "wins,losses = 0,0\n",
    "win_percentage_dp = []\n",
    "for t in range(1,31):\n",
    "    V, p = dynamic_programming(env, t)\n",
    "    for i in range(int(1e5)):\n",
    "        path = env.simulate(start,p)\n",
    "        if path[-1] == (1,1,1,1):\n",
    "            wins +=1\n",
    "        else:\n",
    "            losses +=1\n",
    "    win_percentage_dp.append(wins/(wins + losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc48ea-b12e-497d-8783-d230f012c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([i for i in range(len(win_percentage_dp))],win_percentage_dp )\n",
    "plt.title(\"Win Percentage vs Horizon\")\n",
    "plt.xlabel('Horizon')\n",
    "plt.ylabel('Percentage')\n",
    "plt.savefig('dp_win_percentage.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14265e92-20bb-4dfd-9cea-f9381dd89212",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cddf46d-3ea1-4ddd-9e6b-9a41cd014899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discount Factor \n",
    "gamma   = 29/30; \n",
    "# Accuracy treshold \n",
    "epsilon = 0.0001;\n",
    "\n",
    "env = Maze1(maze, STEP_REWARD = -1, GOAL_REWARD = 5, min_move=0)\n",
    "V, p = value_iteration(env, gamma, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab3676-11fc-450e-920c-16348b71aa3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = env.simulate(start,p,method='ValIter')\n",
    "animate_solution(maze,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98afffe-24c3-4a72-8104-6bb5222b13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = (0,0,6,5)\n",
    "# Discount Factor \n",
    "gamma   = 29/30; \n",
    "# Accuracy treshold \n",
    "epsilon = 0.0001;\n",
    "\n",
    "wins,losses = 0,0\n",
    "win_percentage_vi = []\n",
    "env = Maze1(maze, STEP_REWARD = -1, GOAL_REWARD = 2, min_move=0)\n",
    "V, p = value_iteration(env, gamma,epsilon)\n",
    "for t in range(int(1e4)):\n",
    "    path = env.simulate(start,p,method='ValIter')\n",
    "    if path[-1] == (1,1,1,1) and len(path) - 1 <= 30:\n",
    "        wins +=1\n",
    "    else:\n",
    "        losses +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49238f6-ea96-4380-984d-127f0e46e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wins/(wins + losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d81c159-7811-43e6-81a8-b216b517b440",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d231b2-faf7-46ee-baa1-e928b432a498",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = Maze1(maze, STEP_REWARD = 0, GOAL_REWARD = 1, min_move=0)\n",
    "Q, p, iv = Q_learning(env, gamma, 0.2, 50000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e091b-961f-4525-878f-78e245d825fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b46aae-96a3-4fdf-9e61-2d58fddbc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = env.simulate(start,p,method='ValIter')\n",
    "animate_solution(maze,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9cdb7-dfe4-49a6-829f-3a0cd94c3a75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "9eebca5f-d808-473c-b176-873a8636474c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Episode: 1\n",
      "Episode: 2\n",
      "Episode: 3\n",
      "Episode: 4\n",
      "Episode: 5\n",
      "Episode: 6\n",
      "Episode: 7\n",
      "Episode: 8\n",
      "Episode: 9\n",
      "Episode: 10\n",
      "Episode: 11\n",
      "Episode: 12\n",
      "Episode: 13\n",
      "Episode: 14\n",
      "Episode: 15\n",
      "Episode: 16\n",
      "Episode: 17\n",
      "Episode: 18\n",
      "Episode: 19\n",
      "Episode: 20\n",
      "Episode: 21\n",
      "Episode: 22\n",
      "Episode: 23\n",
      "Episode: 24\n",
      "Episode: 25\n",
      "Episode: 26\n",
      "Episode: 27\n",
      "Episode: 28\n",
      "Episode: 29\n",
      "Episode: 30\n",
      "Episode: 31\n",
      "Episode: 32\n",
      "Episode: 33\n",
      "Episode: 34\n",
      "Episode: 35\n",
      "Episode: 36\n",
      "Episode: 37\n",
      "Episode: 38\n",
      "Episode: 39\n",
      "Episode: 40\n",
      "Episode: 41\n",
      "Episode: 42\n",
      "Episode: 43\n",
      "Episode: 44\n",
      "Episode: 45\n",
      "Episode: 46\n",
      "Episode: 47\n",
      "Episode: 48\n",
      "Episode: 49\n",
      "Episode: 50\n",
      "Episode: 51\n",
      "Episode: 52\n",
      "Episode: 53\n",
      "Episode: 54\n",
      "Episode: 55\n",
      "Episode: 56\n",
      "Episode: 57\n",
      "Episode: 58\n",
      "Episode: 59\n",
      "Episode: 60\n",
      "Episode: 61\n",
      "Episode: 62\n",
      "Episode: 63\n",
      "Episode: 64\n",
      "Episode: 65\n",
      "Episode: 66\n",
      "Episode: 67\n",
      "Episode: 68\n",
      "Episode: 69\n",
      "Episode: 70\n",
      "Episode: 71\n",
      "Episode: 72\n",
      "Episode: 73\n",
      "Episode: 74\n",
      "Episode: 75\n",
      "Episode: 76\n",
      "Episode: 77\n",
      "Episode: 78\n",
      "Episode: 79\n",
      "Episode: 80\n",
      "Episode: 81\n",
      "Episode: 82\n",
      "Episode: 83\n",
      "Episode: 84\n",
      "Episode: 85\n",
      "Episode: 86\n",
      "Episode: 87\n",
      "Episode: 88\n",
      "Episode: 89\n",
      "Episode: 90\n",
      "Episode: 91\n",
      "Episode: 92\n",
      "Episode: 93\n",
      "Episode: 94\n",
      "Episode: 95\n",
      "Episode: 96\n",
      "Episode: 97\n",
      "Episode: 98\n",
      "Episode: 99\n",
      "Episode: 100\n",
      "Episode: 101\n",
      "Episode: 102\n",
      "Episode: 103\n",
      "Episode: 104\n",
      "Episode: 105\n",
      "Episode: 106\n",
      "Episode: 107\n",
      "Episode: 108\n",
      "Episode: 109\n",
      "Episode: 110\n",
      "Episode: 111\n",
      "Episode: 112\n",
      "Episode: 113\n",
      "Episode: 114\n",
      "Episode: 115\n",
      "Episode: 116\n",
      "Episode: 117\n",
      "Episode: 118\n",
      "Episode: 119\n",
      "Episode: 120\n",
      "Episode: 121\n",
      "Episode: 122\n",
      "Episode: 123\n",
      "Episode: 124\n",
      "Episode: 125\n",
      "Episode: 126\n",
      "Episode: 127\n",
      "Episode: 128\n",
      "Episode: 129\n",
      "Episode: 130\n",
      "Episode: 131\n",
      "Episode: 132\n",
      "Episode: 133\n",
      "Episode: 134\n",
      "Episode: 135\n",
      "Episode: 136\n",
      "Episode: 137\n",
      "Episode: 138\n",
      "Episode: 139\n",
      "Episode: 140\n",
      "Episode: 141\n",
      "Episode: 142\n",
      "Episode: 143\n",
      "Episode: 144\n",
      "Episode: 145\n",
      "Episode: 146\n",
      "Episode: 147\n",
      "Episode: 148\n",
      "Episode: 149\n",
      "Episode: 150\n",
      "Episode: 151\n",
      "Episode: 152\n",
      "Episode: 153\n",
      "Episode: 154\n",
      "Episode: 155\n",
      "Episode: 156\n",
      "Episode: 157\n",
      "Episode: 158\n",
      "Episode: 159\n",
      "Episode: 160\n",
      "Episode: 161\n",
      "Episode: 162\n",
      "Episode: 163\n",
      "Episode: 164\n",
      "Episode: 165\n",
      "Episode: 166\n",
      "Episode: 167\n",
      "Episode: 168\n",
      "Episode: 169\n",
      "Episode: 170\n",
      "Episode: 171\n",
      "Episode: 172\n",
      "Episode: 173\n",
      "Episode: 174\n",
      "Episode: 175\n",
      "Episode: 176\n",
      "Episode: 177\n",
      "Episode: 178\n",
      "Episode: 179\n",
      "Episode: 180\n",
      "Episode: 181\n",
      "Episode: 182\n",
      "Episode: 183\n",
      "Episode: 184\n",
      "Episode: 185\n",
      "Episode: 186\n",
      "Episode: 187\n",
      "Episode: 188\n",
      "Episode: 189\n",
      "Episode: 190\n",
      "Episode: 191\n",
      "Episode: 192\n",
      "Episode: 193\n",
      "Episode: 194\n",
      "Episode: 195\n",
      "Episode: 196\n",
      "Episode: 197\n",
      "Episode: 198\n",
      "Episode: 199\n",
      "Episode: 200\n",
      "Episode: 201\n",
      "Episode: 202\n",
      "Episode: 203\n",
      "Episode: 204\n",
      "Episode: 205\n",
      "Episode: 206\n",
      "Episode: 207\n",
      "Episode: 208\n",
      "Episode: 209\n",
      "Episode: 210\n",
      "Episode: 211\n",
      "Episode: 212\n",
      "Episode: 213\n",
      "Episode: 214\n",
      "Episode: 215\n",
      "Episode: 216\n",
      "Episode: 217\n",
      "Episode: 218\n",
      "Episode: 219\n",
      "Episode: 220\n",
      "Episode: 221\n",
      "Episode: 222\n",
      "Episode: 223\n",
      "Episode: 224\n",
      "Episode: 225\n",
      "Episode: 226\n",
      "Episode: 227\n",
      "Episode: 228\n",
      "Episode: 229\n",
      "Episode: 230\n",
      "Episode: 231\n",
      "Episode: 232\n",
      "Episode: 233\n",
      "Episode: 234\n",
      "Episode: 235\n",
      "Episode: 236\n",
      "Episode: 237\n",
      "Episode: 238\n",
      "Episode: 239\n",
      "Episode: 240\n",
      "Episode: 241\n",
      "Episode: 242\n",
      "Episode: 243\n",
      "Episode: 244\n",
      "Episode: 245\n",
      "Episode: 246\n",
      "Episode: 247\n",
      "Episode: 248\n",
      "Episode: 249\n",
      "Episode: 250\n",
      "Episode: 251\n",
      "Episode: 252\n",
      "Episode: 253\n",
      "Episode: 254\n",
      "Episode: 255\n",
      "Episode: 256\n",
      "Episode: 257\n",
      "Episode: 258\n",
      "Episode: 259\n",
      "Episode: 260\n",
      "Episode: 261\n",
      "Episode: 262\n",
      "Episode: 263\n",
      "Episode: 264\n",
      "Episode: 265\n",
      "Episode: 266\n",
      "Episode: 267\n",
      "Episode: 268\n",
      "Episode: 269\n",
      "Episode: 270\n",
      "Episode: 271\n",
      "Episode: 272\n",
      "Episode: 273\n",
      "Episode: 274\n",
      "Episode: 275\n",
      "Episode: 276\n",
      "Episode: 277\n",
      "Episode: 278\n",
      "Episode: 279\n",
      "Episode: 280\n",
      "Episode: 281\n",
      "Episode: 282\n",
      "Episode: 283\n",
      "Episode: 284\n",
      "Episode: 285\n",
      "Episode: 286\n",
      "Episode: 287\n",
      "Episode: 288\n",
      "Episode: 289\n",
      "Episode: 290\n",
      "Episode: 291\n",
      "Episode: 292\n",
      "Episode: 293\n",
      "Episode: 294\n",
      "Episode: 295\n",
      "Episode: 296\n",
      "Episode: 297\n",
      "Episode: 298\n",
      "Episode: 299\n",
      "Episode: 300\n",
      "Episode: 301\n",
      "Episode: 302\n",
      "Episode: 303\n",
      "Episode: 304\n",
      "Episode: 305\n",
      "Episode: 306\n",
      "Episode: 307\n",
      "Episode: 308\n",
      "Episode: 309\n",
      "Episode: 310\n",
      "Episode: 311\n",
      "Episode: 312\n",
      "Episode: 313\n",
      "Episode: 314\n",
      "Episode: 315\n",
      "Episode: 316\n",
      "Episode: 317\n",
      "Episode: 318\n",
      "Episode: 319\n",
      "Episode: 320\n",
      "Episode: 321\n",
      "Episode: 322\n",
      "Episode: 323\n",
      "Episode: 324\n",
      "Episode: 325\n",
      "Episode: 326\n",
      "Episode: 327\n",
      "Episode: 328\n",
      "Episode: 329\n",
      "Episode: 330\n",
      "Episode: 331\n",
      "Episode: 332\n",
      "Episode: 333\n",
      "Episode: 334\n",
      "Episode: 335\n",
      "Episode: 336\n",
      "Episode: 337\n",
      "Episode: 338\n",
      "Episode: 339\n",
      "Episode: 340\n",
      "Episode: 341\n",
      "Episode: 342\n",
      "Episode: 343\n",
      "Episode: 344\n",
      "Episode: 345\n",
      "Episode: 346\n",
      "Episode: 347\n",
      "Episode: 348\n",
      "Episode: 349\n",
      "Episode: 350\n",
      "Episode: 351\n",
      "Episode: 352\n",
      "Episode: 353\n",
      "Episode: 354\n",
      "Episode: 355\n",
      "Episode: 356\n",
      "Episode: 357\n",
      "Episode: 358\n",
      "Episode: 359\n",
      "Episode: 360\n",
      "Episode: 361\n",
      "Episode: 362\n",
      "Episode: 363\n",
      "Episode: 364\n",
      "Episode: 365\n",
      "Episode: 366\n",
      "Episode: 367\n",
      "Episode: 368\n",
      "Episode: 369\n",
      "Episode: 370\n",
      "Episode: 371\n",
      "Episode: 372\n",
      "Episode: 373\n",
      "Episode: 374\n",
      "Episode: 375\n",
      "Episode: 376\n",
      "Episode: 377\n",
      "Episode: 378\n",
      "Episode: 379\n",
      "Episode: 380\n",
      "Episode: 381\n",
      "Episode: 382\n",
      "Episode: 383\n",
      "Episode: 384\n",
      "Episode: 385\n",
      "Episode: 386\n",
      "Episode: 387\n",
      "Episode: 388\n",
      "Episode: 389\n",
      "Episode: 390\n",
      "Episode: 391\n",
      "Episode: 392\n",
      "Episode: 393\n",
      "Episode: 394\n",
      "Episode: 395\n",
      "Episode: 396\n",
      "Episode: 397\n",
      "Episode: 398\n",
      "Episode: 399\n",
      "Episode: 400\n",
      "Episode: 401\n",
      "Episode: 402\n",
      "Episode: 403\n",
      "Episode: 404\n",
      "Episode: 405\n",
      "Episode: 406\n",
      "Episode: 407\n",
      "Episode: 408\n",
      "Episode: 409\n",
      "Episode: 410\n",
      "Episode: 411\n",
      "Episode: 412\n",
      "Episode: 413\n",
      "Episode: 414\n",
      "Episode: 415\n",
      "Episode: 416\n",
      "Episode: 417\n",
      "Episode: 418\n",
      "Episode: 419\n",
      "Episode: 420\n",
      "Episode: 421\n",
      "Episode: 422\n",
      "Episode: 423\n",
      "Episode: 424\n",
      "Episode: 425\n",
      "Episode: 426\n",
      "Episode: 427\n",
      "Episode: 428\n",
      "Episode: 429\n",
      "Episode: 430\n",
      "Episode: 431\n",
      "Episode: 432\n",
      "Episode: 433\n",
      "Episode: 434\n",
      "Episode: 435\n",
      "Episode: 436\n",
      "Episode: 437\n",
      "Episode: 438\n",
      "Episode: 439\n",
      "Episode: 440\n",
      "Episode: 441\n",
      "Episode: 442\n",
      "Episode: 443\n",
      "Episode: 444\n",
      "Episode: 445\n",
      "Episode: 446\n",
      "Episode: 447\n",
      "Episode: 448\n",
      "Episode: 449\n",
      "Episode: 450\n",
      "Episode: 451\n",
      "Episode: 452\n",
      "Episode: 453\n",
      "Episode: 454\n",
      "Episode: 455\n",
      "Episode: 456\n",
      "Episode: 457\n",
      "Episode: 458\n",
      "Episode: 459\n",
      "Episode: 460\n",
      "Episode: 461\n",
      "Episode: 462\n",
      "Episode: 463\n",
      "Episode: 464\n",
      "Episode: 465\n",
      "Episode: 466\n",
      "Episode: 467\n",
      "Episode: 468\n",
      "Episode: 469\n",
      "Episode: 470\n",
      "Episode: 471\n",
      "Episode: 472\n",
      "Episode: 473\n",
      "Episode: 474\n",
      "Episode: 475\n",
      "Episode: 476\n",
      "Episode: 477\n",
      "Episode: 478\n",
      "Episode: 479\n",
      "Episode: 480\n",
      "Episode: 481\n",
      "Episode: 482\n",
      "Episode: 483\n",
      "Episode: 484\n",
      "Episode: 485\n",
      "Episode: 486\n",
      "Episode: 487\n",
      "Episode: 488\n",
      "Episode: 489\n",
      "Episode: 490\n",
      "Episode: 491\n",
      "Episode: 492\n",
      "Episode: 493\n",
      "Episode: 494\n",
      "Episode: 495\n",
      "Episode: 496\n",
      "Episode: 497\n",
      "Episode: 498\n",
      "Episode: 499\n"
     ]
    }
   ],
   "source": [
    "env = Maze1(maze, STEP_REWARD = 0, GOAL_REWARD = 1, min_move=0)\n",
    "Q, p, iv = sarsa(env, 2/3, gamma, 0.2, 500, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "bbdd9184-007c-49e0-a664-141f374e440f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f3f8045b70>]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "a482b389-66e4-4e56-a984-b3b679fdbcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = env.simulate(start,p,method='ValIter')\n",
    "animate_solution(maze,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94cc8a-03f1-4f5a-b88c-7367f8a68d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
